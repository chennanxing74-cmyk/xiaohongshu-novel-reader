#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„èµ·ç‚¹å°è¯´çˆ¬è™«
ä¸“é—¨ç”¨äºçˆ¬å–èµ·ç‚¹å°è¯´å¹¶ç”Ÿæˆå°çº¢ä¹¦é£æ ¼çš„å±•ç¤ºé¡µé¢
"""

import os
import re
import json
import time
import random
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import logging
from typing import Dict, List, Optional
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SimpleQidianCrawler:
    """ç®€å•çš„èµ·ç‚¹å°è¯´çˆ¬è™«"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        })
        
        # é¢„å®šä¹‰çš„çƒ­é—¨å°è¯´æ•°æ®ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
        self.demo_novels = [
            {
                "id": "1045191725",
                "title": "æ—§åŸŸæ€ªè¯",
                "author": "æœªçŸ¥ä½œè€…",
                "category": "éƒ½å¸‚çµå¼‚",
                "description": "å¤œå¹•é™ä¸´ï¼Œå¤è€çš„è¡—é“ä¸Šåªæœ‰å‡ ç›æ˜é»„çš„è·¯ç¯åœ¨æ‘‡æ›³ã€‚æ—å¢¨æ¨å¼€é‚£æ‰‡å±å‘€ä½œå“çš„æœ¨é—¨ï¼Œèµ°è¿›äº†è¿™å®¶åä¸º'æ—§åŸŸ'çš„å¤ä¹¦åº—...",
                "cover": "https://via.placeholder.com/300x400/667eea/ffffff?text=æ—§åŸŸæ€ªè¯",
                "tags": ["éƒ½å¸‚", "çµå¼‚", "æ‚¬ç–‘", "å®ˆå¤œäºº"],
                "status": "è¿è½½ä¸­",
                "word_count": 156000,
                "chapters": 45,
                "rating": 4.8,
                "views": 128000,
                "likes": 8900,
                "comments": 1200
            },
            {
                "id": "1124168",
                "title": "æ–—ç ´è‹ç©¹",
                "author": "å¤©èš•åœŸè±†",
                "category": "ç„å¹»å¥‡å¹»",
                "description": "è¿™é‡Œæ˜¯æ–—æ°”å¤§é™†ï¼Œæ²¡æœ‰èŠ±ä¿çš„é­”æ³•ï¼Œæœ‰çš„ï¼Œä»…ä»…æ˜¯ç¹è¡åˆ°å·…å³°çš„æ–—æ°”ï¼åœ¨è¿™ä¸ªä¸–ç•Œï¼Œè¦æƒ³æˆä¸ºé‚£ç«™åœ¨å¤§é™†å·…å³°çš„æ–—å¸å¼ºè€…...",
                "cover": "https://via.placeholder.com/300x400/764ba2/ffffff?text=æ–—ç ´è‹ç©¹",
                "tags": ["ç„å¹»", "çƒ­è¡€", "å‡çº§", "ç‚¼è¯"],
                "status": "å·²å®Œç»“",
                "word_count": 5400000,
                "chapters": 1648,
                "rating": 4.9,
                "views": 9800000,
                "likes": 456000,
                "comments": 89000
            },
            {
                "id": "1003354631",
                "title": "å®Œç¾ä¸–ç•Œ",
                "author": "è¾°ä¸œ",
                "category": "ç„å¹»å¥‡å¹»",
                "description": "ä¸€ç²’å°˜å¯å¡«æµ·ï¼Œä¸€æ ¹è‰æ–©å°½æ—¥æœˆæ˜Ÿè¾°ï¼Œå¼¹æŒ‡é—´å¤©ç¿»åœ°è¦†ã€‚ç¾¤é›„å¹¶èµ·ï¼Œä¸‡æ—æ—ç«‹ï¼Œè¯¸åœ£äº‰éœ¸ï¼Œä¹±å¤©åŠ¨åœ°...",
                "cover": "https://via.placeholder.com/300x400/f093fb/ffffff?text=å®Œç¾ä¸–ç•Œ",
                "tags": ["ç„å¹»", "çƒ­è¡€", "ä»™ä¾ ", "æˆé•¿"],
                "status": "å·²å®Œç»“",
                "word_count": 7200000,
                "chapters": 1928,
                "rating": 4.7,
                "views": 12000000,
                "likes": 678000,
                "comments": 156000
            },
            {
                "id": "1010868264",
                "title": "è¯¡ç§˜ä¹‹ä¸»",
                "author": "çˆ±æ½œæ°´çš„ä¹Œè´¼",
                "category": "å¥‡å¹»ç„å¹»",
                "description": "è’¸æ±½ä¸æœºæ¢°çš„æ—¶ä»£ï¼Œè°èƒ½è§¦åŠéå‡¡ï¼Ÿå†å²å’Œé»‘æš—çš„è¿·é›¾é‡Œï¼Œåˆæ˜¯è°åœ¨è€³è¯­ï¼Ÿæˆ‘ä»è¯¡ç§˜ä¸­é†’æ¥ï¼Œççœ¼çœ‹è§è¿™ä¸ªä¸–ç•Œ...",
                "cover": "https://via.placeholder.com/300x400/4facfe/ffffff?text=è¯¡ç§˜ä¹‹ä¸»",
                "tags": ["å¥‡å¹»", "å…‹è‹é²", "è’¸æ±½æœ‹å…‹", "ç¥ç§˜"],
                "status": "å·²å®Œç»“",
                "word_count": 3800000,
                "chapters": 1394,
                "rating": 4.9,
                "views": 8500000,
                "likes": 567000,
                "comments": 234000
            },
            {
                "id": "1887208",
                "title": "é®å¤©",
                "author": "è¾°ä¸œ",
                "category": "ç„å¹»å¥‡å¹»",
                "description": "å†°å†·ä¸é»‘æš—å¹¶å­˜çš„å®‡å®™æ·±å¤„ï¼Œä¹å…·åºå¤§çš„é¾™å°¸æ‹‰ç€ä¸€å£é’é“œå¤æ£ºï¼Œäº˜å¤é•¿å­˜ã€‚è¿™æ˜¯å¤ªç©ºæ¢æµ‹å™¨åœ¨æ¯å¯‚çš„å®‡å®™ä¸­æ•æ‰åˆ°çš„ä¸€å¹…æå…¶éœ‡æ’¼çš„ç”»é¢...",
                "cover": "https://via.placeholder.com/300x400/00d4aa/ffffff?text=é®å¤©",
                "tags": ["ç„å¹»", "ä¿®ä»™", "çƒ­è¡€", "å¤é£"],
                "status": "å·²å®Œç»“",
                "word_count": 6900000,
                "chapters": 1875,
                "rating": 4.8,
                "views": 15000000,
                "likes": 789000,
                "comments": 298000
            },
            {
                "id": "1234567",
                "title": "å…¨èŒé«˜æ‰‹",
                "author": "è´è¶è“",
                "category": "æ¸¸æˆç«æŠ€",
                "description": "ç½‘æ¸¸è£è€€ä¸­è¢«èª‰ä¸ºæ•™ç§‘ä¹¦çº§åˆ«çš„é¡¶å°–é«˜æ‰‹ï¼Œå› ä¸ºç§ç§åŸå› é­åˆ°ä¿±ä¹éƒ¨çš„é©±é€ï¼Œç¦»å¼€èŒä¸šåœˆçš„ä»–å¯„èº«äºä¸€å®¶ç½‘å§æˆäº†ä¸€ä¸ªå°å°çš„ç½‘ç®¡...",
                "cover": "https://via.placeholder.com/300x400/ff6b6b/ffffff?text=å…¨èŒé«˜æ‰‹",
                "tags": ["æ¸¸æˆ", "ç«æŠ€", "çƒ­è¡€", "å›¢é˜Ÿ"],
                "status": "å·²å®Œç»“",
                "word_count": 5300000,
                "chapters": 1728,
                "rating": 4.6,
                "views": 7800000,
                "likes": 345000,
                "comments": 167000
            }
        ]
    
    def extract_book_id(self, url: str) -> Optional[str]:
        """ä»URLä¸­æå–ä¹¦ç±ID"""
        patterns = [
            r'/book/(\d+)',
            r'/info/(\d+)',
            r'bookId[=:](\d+)',
            r'id[=:](\d+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        
        return None
    
    def get_novel_by_id(self, book_id: str) -> Optional[Dict]:
        """æ ¹æ®IDè·å–å°è¯´ä¿¡æ¯"""
        for novel in self.demo_novels:
            if novel['id'] == book_id:
                return novel
        return None
    
    def get_random_novels(self, count: int = 6) -> List[Dict]:
        """è·å–éšæœºå°è¯´åˆ—è¡¨"""
        return random.sample(self.demo_novels, min(count, len(self.demo_novels)))
    
    def get_novels_by_category(self, category: str = None) -> List[Dict]:
        """æ ¹æ®åˆ†ç±»è·å–å°è¯´"""
        if not category:
            return self.demo_novels
        
        return [novel for novel in self.demo_novels if category in novel['category']]
    
    def search_novels(self, keyword: str) -> List[Dict]:
        """æœç´¢å°è¯´"""
        keyword = keyword.lower()
        results = []
        
        for novel in self.demo_novels:
            if (keyword in novel['title'].lower() or 
                keyword in novel['author'].lower() or 
                keyword in novel['description'].lower() or
                any(keyword in tag.lower() for tag in novel['tags'])):
                results.append(novel)
        
        return results
    
    def get_novel_chapters(self, book_id: str, max_chapters: int = 10) -> List[Dict]:
        """è·å–å°è¯´ç« èŠ‚ï¼ˆæ¼”ç¤ºæ•°æ®ï¼‰"""
        novel = self.get_novel_by_id(book_id)
        if not novel:
            return []
        
        chapters = []
        chapter_templates = [
            "ç¬¬{num}ç«  åˆå…¥{world}",
            "ç¬¬{num}ç«  ç¥ç§˜çš„{item}",
            "ç¬¬{num}ç«  {skill}å¤§æˆ",
            "ç¬¬{num}ç«  ç”Ÿæ­»{battle}",
            "ç¬¬{num}ç«  çªç ´{realm}",
            "ç¬¬{num}ç«  {enemy}æ¥è¢­",
            "ç¬¬{num}ç«  {treasure}ç°ä¸–",
            "ç¬¬{num}ç«  {master}ä¼ æ‰¿",
            "ç¬¬{num}ç«  {city}é£äº‘",
            "ç¬¬{num}ç«  {power}è§‰é†’"
        ]
        
        words = {
            'world': ['æ±Ÿæ¹–', 'ä»™ç•Œ', 'é­”åŸŸ', 'å¤åŸŸ', 'ç¥ç•Œ'],
            'item': ['å®ç‰©', 'ç§˜ç±', 'ç¥å™¨', 'ä¸¹è¯', 'ç¬¦å’’'],
            'skill': ['å‰‘æ³•', 'å¿ƒæ³•', 'ç¥é€š', 'ç§˜æœ¯', 'åŠŸæ³•'],
            'battle': ['å†³æˆ˜', 'è¾ƒé‡', 'å¯¹å†³', 'äº‰é”‹', 'ææ€'],
            'realm': ['å¢ƒç•Œ', 'ç“¶é¢ˆ', 'æ¡æ¢', 'æ·é”', 'æé™'],
            'enemy': ['å¼ºæ•Œ', 'é­”å¤´', 'é‚ªä¿®', 'å¦–å…½', 'æ€æ‰‹'],
            'treasure': ['å®è—', 'é—è¿¹', 'ç§˜å¢ƒ', 'æ´åºœ', 'ä¼ æ‰¿'],
            'master': ['å‰è¾ˆ', 'é«˜äºº', 'å®—å¸ˆ', 'å¤§èƒ½', 'åœ£è€…'],
            'city': ['å¤åŸ', 'ä»™åŸ', 'ç‹åŸ', 'åœ£åŸ', 'é­”åŸ'],
            'power': ['è¡€è„‰', 'å¤©èµ‹', 'æ½œåŠ›', 'çœŸå…ƒ', 'ç¥è¯†']
        }
        
        for i in range(1, min(max_chapters + 1, novel['chapters'] + 1)):
            template = random.choice(chapter_templates)
            title = template.format(
                num=i,
                **{key: random.choice(values) for key, values in words.items()}
            )
            
            chapters.append({
                'number': i,
                'title': title,
                'word_count': random.randint(2000, 5000),
                'update_time': datetime.now().strftime('%Y-%m-%d %H:%M'),
                'is_vip': i > 50 and novel['status'] == 'è¿è½½ä¸­'
            })
        
        return chapters
    
    def save_novels_data(self, novels: List[Dict], filename: str = 'novels_data.json'):
        """ä¿å­˜å°è¯´æ•°æ®åˆ°JSONæ–‡ä»¶"""
        data = {
            'update_time': datetime.now().isoformat(),
            'total_count': len(novels),
            'novels': novels
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"å°è¯´æ•°æ®å·²ä¿å­˜åˆ° {filename}")
    
    def crawl_novels(self, urls: List[str] = None, save_file: bool = True) -> List[Dict]:
        """çˆ¬å–å°è¯´æ•°æ®"""
        print("ğŸš€ å¼€å§‹çˆ¬å–èµ·ç‚¹å°è¯´æ•°æ®...")
        
        if urls:
            # ä»URLæå–ä¹¦ç±ID
            novels = []
            for url in urls:
                book_id = self.extract_book_id(url)
                if book_id:
                    novel = self.get_novel_by_id(book_id)
                    if novel:
                        novels.append(novel)
                        print(f"âœ… è·å–å°è¯´: {novel['title']}")
                    else:
                        print(f"âŒ æœªæ‰¾åˆ°ä¹¦ç±ID {book_id} å¯¹åº”çš„å°è¯´")
                else:
                    print(f"âŒ æ— æ³•ä»URLæå–ä¹¦ç±ID: {url}")
        else:
            # è·å–æ‰€æœ‰æ¼”ç¤ºå°è¯´
            novels = self.demo_novels
            print(f"âœ… è·å– {len(novels)} æœ¬æ¼”ç¤ºå°è¯´")
        
        if save_file:
            self.save_novels_data(novels)
        
        print(f"ğŸ‰ çˆ¬å–å®Œæˆï¼å…±è·å– {len(novels)} æœ¬å°è¯´")
        return novels

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    print("ğŸ“š ç®€å•èµ·ç‚¹å°è¯´çˆ¬è™«")
    print("=" * 40)
    
    crawler = SimpleQidianCrawler()
    
    if len(sys.argv) > 1:
        # ä»å‘½ä»¤è¡Œå‚æ•°è·å–URL
        urls = sys.argv[1:]
        novels = crawler.crawl_novels(urls)
    else:
        # ä½¿ç”¨æ¼”ç¤ºæ•°æ®
        print("ğŸ’¡ æœªæä¾›URLï¼Œä½¿ç”¨æ¼”ç¤ºæ•°æ®")
        novels = crawler.crawl_novels()
    
    print(f"\nğŸ“Š çˆ¬å–ç»“æœ:")
    for novel in novels:
        print(f"  ğŸ“– {novel['title']} - {novel['author']}")
        print(f"     åˆ†ç±»: {novel['category']} | çŠ¶æ€: {novel['status']}")
        print(f"     å­—æ•°: {novel['word_count']:,} | ç« èŠ‚: {novel['chapters']}")
        print()

if __name__ == "__main__":
    main()
